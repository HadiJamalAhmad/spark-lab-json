[0m[[0m[0mdebug[0m] [0m[0m> Exec(early(addDefaultCommands), None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(addDefaultCommands, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(early(initialize), None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(initialize, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(boot, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(writeSbtVersion, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(reload, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(sbtStashOnFailure, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(onFailure loadFailed, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(loadp, None, None)[0m
[0m[[0m[0minfo[0m] [0m[0mwelcome to sbt 1.6.1 (Eclipse Adoptium Java 11.0.14.1)[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.defaultLoad until apply took 173.534299ms[0m
[0m[[0m[0mdebug[0m] [0m[0m                Load.loadUnit: plugins took 43.092601ms[0m
[0m[[0m[0mdebug[0m] [0m[0m                Load.loadUnit: defsScala took 0.152399ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Scanning directory C:\Users\hadij\Downloads\spark-lab-json\project\project[0m
[0m[[0m[0mdebug[0m] [0m[0m                  Load.loadUnit: mkEval took 3.512999ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Found non-root projects [0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json\project\project, returning: ()[0m
[0m[[0m[0mdebug[0m] [0m[0mdeducing auto plugins based on known facts Set(Atom(sbt.plugins.CorePlugin)) and clauses Clauses(Clause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.ScriptedPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SbtPlugin),Set(Atom(sbt.ScriptedPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SemanticdbPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JUnitXmlReportPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.MiniDependencyTreePlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.IvyPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.SemanticdbPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.JUnitXmlReportPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.Giter8TemplatePlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.MiniDependencyTreePlugin))))[0m
[0m[[0m[0mdebug[0m] [0m[0m  :: deduced result: Matched(sbt.plugins.CorePlugin,sbt.plugins.Giter8TemplatePlugin,sbt.plugins.IvyPlugin,sbt.plugins.JvmPlugin,sbt.plugins.MiniDependencyTreePlugin,sbt.plugins.JUnitXmlReportPlugin,sbt.plugins.SemanticdbPlugin)[0m
[0m[[0m[0mdebug[0m] [0m[0mPlugins.deducer#function took 9.837699 ms[0m
[0m[[0m[0minfo[0m] [0m[0mloading settings for project spark-lab-json-build-build from metals.sbt ...[0m
[0m[[0m[0mdebug[0m] [0m[0m                    Load.resolveProject(spark-lab-json-build-build) took 30.941799ms[0m
[0m[[0m[0mdebug[0m] [0m[0m                  Load.loadTransitive: finalizeProject(Project(id spark-lab-json-build-build, base: C:\Users\hadij\Downloads\spark-lab-json\project\project, plugins: List(<none>))) took 55.935099ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json\project\project, returning: (spark-lab-json-build-build)[0m
[0m[[0m[0mdebug[0m] [0m[0m                Load.loadUnit: loadedProjectsRaw took 178.059599ms[0m
[0m[[0m[0mdebug[0m] [0m[0m                Load.loadUnit: cleanEvalClasses took 4.2208ms[0m
[0m[[0m[0mdebug[0m] [0m[0m              Load.loadUnit(file:/C:/Users/hadij/Downloads/spark-lab-json/project/project/, ...) took 228.6376ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: load took 293.1337ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: resolveProjects took 3.006801ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: finalTransforms took 33.318901ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: config.delegates took 4.1913ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: Def.make(settings)... took 213.5057ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: structureIndex took 53.2214ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.apply: mkStreams took 0.991ms[0m
[0m[[0m[0minfo[0m] [0m[0mloading project definition from C:\Users\hadij\Downloads\spark-lab-json\project\project[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0m          Load.loadUnit: plugins took 1201.6262ms[0m
[0m[[0m[0mdebug[0m] [0m[0m          Load.loadUnit: defsScala took 0.002101ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Scanning directory C:\Users\hadij\Downloads\spark-lab-json\project[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.loadUnit: mkEval took 0.2072ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Found non-root projects [0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json\project, returning: ()[0m
[0m[[0m[0mdebug[0m] [0m[0mdeducing auto plugins based on known facts Set(Atom(sbt.plugins.CorePlugin)) and clauses Clauses(Clause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.ScriptedPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SbtPlugin),Set(Atom(sbt.ScriptedPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SemanticdbPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JUnitXmlReportPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.MiniDependencyTreePlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(bloop.integrations.sbt.BloopPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.IvyPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.SemanticdbPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.JUnitXmlReportPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.Giter8TemplatePlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.MiniDependencyTreePlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(bloop.integrations.sbt.BloopPlugin))))[0m
[0m[[0m[0mdebug[0m] [0m[0m  :: deduced result: Matched(sbt.plugins.CorePlugin,sbt.plugins.Giter8TemplatePlugin,sbt.plugins.IvyPlugin,sbt.plugins.JvmPlugin,bloop.integrations.sbt.BloopPlugin,sbt.plugins.MiniDependencyTreePlugin,sbt.plugins.JUnitXmlReportPlugin,sbt.plugins.SemanticdbPlugin)[0m
[0m[[0m[0mdebug[0m] [0m[0mPlugins.deducer#function took 1.136601 ms[0m
[0m[[0m[0minfo[0m] [0m[0mloading settings for project spark-lab-json-build from metals.sbt ...[0m
[0m[[0m[0mdebug[0m] [0m[0m              Load.resolveProject(spark-lab-json-build) took 12.0431ms[0m
[0m[[0m[0mdebug[0m] [0m[0m            Load.loadTransitive: finalizeProject(Project(id spark-lab-json-build, base: C:\Users\hadij\Downloads\spark-lab-json\project, plugins: List(<none>))) took 13.4963ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json\project, returning: (spark-lab-json-build)[0m
[0m[[0m[0mdebug[0m] [0m[0m          Load.loadUnit: loadedProjectsRaw took 29.771401ms[0m
[0m[[0m[0mdebug[0m] [0m[0m          Load.loadUnit: cleanEvalClasses took 0.8406ms[0m
[0m[[0m[0mdebug[0m] [0m[0m        Load.loadUnit(file:/C:/Users/hadij/Downloads/spark-lab-json/project/, ...) took 1232.8394ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: load took 1233.907001ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: resolveProjects took 0.0648ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: finalTransforms took 9.1018ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: config.delegates took 0.174001ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: Def.make(settings)... took 39.584299ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: structureIndex took 17.0685ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.apply: mkStreams took 0.002401ms[0m
[0m[[0m[0minfo[0m] [0m[0mloading project definition from C:\Users\hadij\Downloads\spark-lab-json\project[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: bloopInstall[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[32msuccess[0m] [0m[0mGenerated .bloop\spark-lab-json-build.json[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 0 s, completed 3 mars 2022 Ã  09:59:05[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0m    Load.loadUnit: plugins took 1935.120599ms[0m
[0m[[0m[0mdebug[0m] [0m[0m    Load.loadUnit: defsScala took 0.001799ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Scanning directory C:\Users\hadij\Downloads\spark-lab-json[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.loadUnit: mkEval took 0.2112ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Found non-root projects [0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json, returning: ()[0m
[0m[[0m[0mdebug[0m] [0m[0mdeducing auto plugins based on known facts Set(Atom(sbt.plugins.CorePlugin)) and clauses Clauses(Clause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.ScriptedPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SbtPlugin),Set(Atom(sbt.ScriptedPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.SemanticdbPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JUnitXmlReportPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.MiniDependencyTreePlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(bloop.integrations.sbt.BloopPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.IvyPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.IvyPlugin),Set(Atom(sbt.plugins.JvmPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.SemanticdbPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.JUnitXmlReportPlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.CorePlugin),Set(Atom(sbt.plugins.Giter8TemplatePlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(sbt.plugins.MiniDependencyTreePlugin)))[0m
[0m[[0m[0mdebug[0m] [0m[0mClause(Atom(sbt.plugins.JvmPlugin),Set(Atom(bloop.integrations.sbt.BloopPlugin))))[0m
[0m[[0m[0mdebug[0m] [0m[0m  :: deduced result: Matched(sbt.plugins.CorePlugin,sbt.plugins.Giter8TemplatePlugin,sbt.plugins.IvyPlugin,sbt.plugins.JvmPlugin,bloop.integrations.sbt.BloopPlugin,sbt.plugins.MiniDependencyTreePlugin,sbt.plugins.JUnitXmlReportPlugin,sbt.plugins.SemanticdbPlugin)[0m
[0m[[0m[0mdebug[0m] [0m[0mPlugins.deducer#function took 0.8777 ms[0m
[0m[[0m[0minfo[0m] [0m[0mloading settings for project spark-lab-json from build.sbt ...[0m
[0m[[0m[0mdebug[0m] [0m[0m        Load.resolveProject(spark-lab-json) took 11.0188ms[0m
[0m[[0m[0mdebug[0m] [0m[0m      Load.loadTransitive: finalizeProject(Project(id spark-lab-json, base: C:\Users\hadij\Downloads\spark-lab-json, plugins: List(<none>))) took 12.177101ms[0m
[0m[[0m[0mdebug[0m] [0m[0m[Loading] Done in C:\Users\hadij\Downloads\spark-lab-json, returning: (spark-lab-json)[0m
[0m[[0m[0mdebug[0m] [0m[0m    Load.loadUnit: loadedProjectsRaw took 77.2873ms[0m
[0m[[0m[0mdebug[0m] [0m[0m    Load.loadUnit: cleanEvalClasses took 2.5001ms[0m
[0m[[0m[0mdebug[0m] [0m[0m  Load.loadUnit(file:/C:/Users/hadij/Downloads/spark-lab-json/, ...) took 2015.567701ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: load took 2025.7757ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: resolveProjects took 0.0918ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: finalTransforms took 7.978299ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: config.delegates took 0.1776ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: Def.make(settings)... took 33.3596ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: structureIndex took 13.1193ms[0m
[0m[[0m[0mdebug[0m] [0m[0mLoad.apply: mkStreams took 0.0029ms[0m
[0m[[0m[0minfo[0m] [0m[0mset current project to Spark Project (in build file:/C:/Users/hadij/Downloads/spark-lab-json/)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(sbtPopOnFailure, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(resumeFromFailure, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(notifyUsersAboutShell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(iflast shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(test, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Test / test[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 8 Scala sources to C:\Users\hadij\Downloads\spark-lab-json\target\scala-2.12\classes ...[0m
[0m[[0m[0minfo[0m] [0m[0mNon-compiled module 'compiler-bridge_2.12' for Scala 2.12.10. Compiling...[0m
[0m[[0m[0minfo[0m] [0m[0m  Compilation completed in 4.56s.[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 5 Scala sources to C:\Users\hadij\Downloads\spark-lab-json\target\scala-2.12\test-classes ...[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEx3HashTagMiningSpec:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should count the hashtag mentioned on tweets *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  scala.NotImplementedError: an implementation is missing[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMining$.hashtagMentionedOnTweet(Ex3HashTagMining.scala:47)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMiningSpec.$anonfun$new$1(Ex3HashTagMiningSpec.scala:11)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:22)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:20)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should count the number of mention by hashtag *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  scala.NotImplementedError: an implementation is missing[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMining$.countMentions(Ex3HashTagMining.scala:55)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMiningSpec.$anonfun$new$2(Ex3HashTagMiningSpec.scala:16)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:22)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:20)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should define the top10 *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  scala.NotImplementedError: an implementation is missing[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMining$.top10HashTags(Ex3HashTagMining.scala:62)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex3HashTagMiningSpec.$anonfun$new$3(Ex3HashTagMiningSpec.scala:22)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:22)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.Transformer.apply(Transformer.scala:20)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.TestSuite.withFixture(TestSuite.scala:196)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEx2TweetMiningSpec:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should count the persons mentioned on tweets *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  scala.NotImplementedError: an implementation is missing[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEx0WordcountSpec:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31mcom.tp.spark.core.Ex0WordcountSpec *** ABORTED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  java.lang.OutOfMemoryError: unable to create native thread: possibly out of memory or process/resource limits reached[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at java.base/java.lang.Thread.start0(Native Method)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at java.base/java.lang.Thread.start(Thread.java:798)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at java.base/java.util.Timer.<init>(Timer.java:177)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at java.base/java.util.Timer.<init>(Timer.java:147)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.scheduler.TaskSchedulerImpl.<init>(TaskSchedulerImpl.scala:155)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:2896)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.SparkContext.<init>(SparkContext.scala:557)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2672)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex0Wordcount$.loadData(Ex0Wordcount.scala:32)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex0WordcountSpec.$anonfun$new$1(Ex0WordcountSpec.scala:12)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex2TweetMining$.mentionOnTweet(Ex2TweetMining.scala:51)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at com.tp.spark.core.Ex2TweetMiningSpec.$anonfun$new$1(Ex2TweetMiningSpec.scala:11)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)[0m[0m
